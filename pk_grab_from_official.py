import requests
from bs4 import BeautifulSoup
import time
import json
import os
import re

def get_soup(url, lang="en"):
    # é‡å°ä¸åŒèªè¨€è¨­å®šæ¨™é ­ï¼Œé¿å…ä¼ºæœå™¨å¼·åˆ¶è½‰å€
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9" if lang == "en" else "zh-TW,zh;q=0.9"
    }
    print(f"ğŸ“¡ GET [{lang}]: {url}")
    res = requests.get(url, headers=headers)
    return BeautifulSoup(res.text, 'html.parser')

def get_leagues_from_article(url, lang="en"):
    soup = get_soup(url, lang)
    items = soup.find_all('div', attrs={"data-slot": "GblScheduleBlockItem"})
    schedule_data = []
    
    for item in items:
        start_ts = int(item.get('data-start-timestamp', 0))
        end_ts = int(item.get('data-end-timestamp', 0))
        
        # æŠ“å–è¯ç›Ÿåç¨±
        league_divs = item.find_all('div', class_=lambda x: x and 'League' in x)
        names = [d.get_text(strip=True).replace('*', '') for d in league_divs if d.get_text(strip=True)]
        
        schedule_data.append({
            "start": start_ts, 
            "end": end_ts, 
            "leagues": names
        })
    return schedule_data

def map_to_pvpoke_id_and_cp(en_name):
    name = en_name.lower()
    cp = 1500
    
    # 1. åˆ¤æ–· CP
    if "master" in name: cp = 10000
    elif "ultra" in name: cp = 2500
    elif "little" in name: cp = 500
    
    # 2. åˆ¤æ–· PvPoke ID
    # æ ¸å¿ƒè¯ç›Ÿè™•ç†
    if "great league" in name and "remix" not in name: return "all", 1500
    if "ultra league" in name and "premier" not in name: return "all", 2500
    if "master league" in name and "premier" not in name: return "all", 10000
    
    # ç‰¹æ®Šç›ƒè³½è™•ç†
    # é‚è¼¯ï¼šç§»é™¤ "Cup", "League", "Edition", "Version" ç­‰é›œè¨Š
    clean_name = name.replace(" cup", "").replace(" league", "").replace(" edition", "").replace(" version", "")
    
    # å–æœ€å¾Œä¸€å€‹å–®å­—ä½œç‚º ID (é€šå¸¸æ˜¯ Cup çš„åå­—ï¼Œå¦‚ "Retro" -> "retro")
    # ä½†é‡åˆ°åƒ "Ultra Premier" é€™ç¨®é›™å­—çš„ï¼Œè¦å°å¿ƒè™•ç†
    if "premier" in clean_name:
        pvp_id = "premier" 
        if "classic" in clean_name: pvp_id = "premierclassic"
    else:
        pvp_id = clean_name.strip().split(" ")[-1]
    
    # 3. å¼·åˆ¶å°æ‡‰è¡¨ (æ‰‹å‹•ä¿®æ­£ä¸€äº› PvPoke å‘½åä¸è¦å‰‡çš„)
    manual_map = {
        "catch": "catch",
        "willpower": "willpower",
        "evolution": "evolution",
        "fantasy": "fantasy",
        "fighting": "fighting",
        "flying": "flying",
        "fossil": "fossil",
        "holiday": "holiday",
        "halloween": "halloween",
        "jungle": "jungle",
        "love": "love",
        "mountain": "mountain",
        "spring": "spring",
        "summer": "summer",
        "sunshine": "sunshine",
        "retro": "retro",
        "remix": "remix"
    }
    
    # å¦‚æœç®—å‡ºä¾†çš„ ID åœ¨å°æ‡‰è¡¨è£¡ï¼Œå°±ç”¨å°æ‡‰è¡¨çš„ (ä¿éšª)
    if pvp_id in manual_map:
        pvp_id = manual_map[pvp_id]

    return pvp_id, cp

def run_automation():
    base_url = "https://pokemongolive.com"
    news_list_url = f"{base_url}/zh_hant/news"
    
    # ç¬¬ä¸€æ¬¡è«‹æ±‚åªç‚ºäº†æ‰¾æ–‡ç« é€£çµ
    soup = get_soup(news_list_url, "zh")
    
    zh_article_url = None
    for a in soup.find_all('a', href=True):
        if "å°æˆ°è¯ç›Ÿ" in a.get_text() and "è³½å­£æ›´æ–°" in a.get_text():
            href = a['href']
            zh_article_url = base_url + href if not href.startswith('http') else href
            break
    
    if not zh_article_url:
        print("âŒ æ‰¾ä¸åˆ°æœ€æ–°çš„å°æˆ°è¯ç›Ÿæ–‡ç« ")
        return

    # â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šä½¿ç”¨ Regex ç„¡è¦–å¤§å°å¯«å–ä»£ â˜…â˜…â˜…
    en_article_url = re.sub(r'/zh[-_]hant/', '/en/', zh_article_url, flags=re.IGNORECASE)
    
    print(f"ğŸ”— é–å®šä¸­æ–‡æ–‡ç« : {zh_article_url}")
    print(f"ğŸ”— é–å®šè‹±æ–‡æ–‡ç« : {en_article_url}")

    zh_data = get_leagues_from_article(zh_article_url, "zh")
    en_data = get_leagues_from_article(en_article_url, "en")
    
    current_ms = int(time.time() * 1000)
    
    manifest = {
        "last_updated_human": time.ctime(),
        "active_leagues": []
    }
    
    # æ¯”å°é‚è¼¯
    for i in range(len(zh_data)):
        # ç¢ºä¿ç´¢å¼•ä¸è¶…å‡ºç¯„åœ (ä»¥é˜²è¬ä¸€ä¸­è‹±æ–‡ç‰ˆå€å¡Šæ•¸é‡ä¸ä¸€è‡´)
        if i >= len(en_data): break
        
        if zh_data[i]['start'] <= current_ms <= zh_data[i]['end']:
            for zh, en in zip(zh_data[i]['leagues'], en_data[i]['leagues']):
                pvp_id, cp = map_to_pvpoke_id_and_cp(en)
                
                print(f"âœ… ç™¼ç¾: {zh} ({en}) -> ID: {pvp_id}, CP: {cp}")
                
                manifest["active_leagues"].append({
                    "name_zh": zh,
                    "name_en": en,
                    "pvpoke_id": pvp_id,
                    "cp": cp,
                    # é å…ˆçµ„å¥½ JSON URL æ–¹ä¾¿ Worker ä½¿ç”¨
                    "file_name": f"rankings_{cp}.json" if pvp_id == "all" else f"rankings_{pvp_id}_{cp}.json"
                })

    os.makedirs('data', exist_ok=True)
    with open('data/manifest.json', 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ‰ å®Œæˆ! ç”¢å‡º {len(manifest['active_leagues'])} ç­†è³‡æ–™ã€‚")

if __name__ == "__main__":
    run_automation()
