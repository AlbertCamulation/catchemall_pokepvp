import requests
from bs4 import BeautifulSoup
import time
import json
import os
import re

# ==========================================
# 1. åŸºç¤è¨­å®š
# ==========================================
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def get_soup(url, lang="en"):
    headers = HEADERS.copy()
    headers["Accept-Language"] = "en-US,en;q=0.9" if lang == "en" else "zh-TW,zh;q=0.9"
    try:
        res = requests.get(url, headers=headers, timeout=10)
        return BeautifulSoup(res.text, 'html.parser')
    except Exception as e:
        print(f"âŒ è«‹æ±‚å¤±æ•—: {e}")
        return None

# ==========================================
# 2. æ ¸å¿ƒï¼šæ™ºæ…§å‹é€£çµæª¢æŸ¥ (Smart Probe)
# ==========================================
def find_valid_pvpoke_url(pvpoke_id, cp):
    """
    æš´åŠ›æ¸¬è©¦ï¼šæ‰¾å‡ºè©²è¯ç›ŸçœŸæ­£å­˜åœ¨çš„ JSON æª”æ¡ˆç¶²å€
    """
    base_repo = "https://raw.githubusercontent.com/pvpoke/pvpoke/master/src/data/rankings"
    
    # é æ¸¬å¯èƒ½çš„è·¯å¾‘çµ„åˆ
    # çµ„åˆ A: æ¨™æº–è·¯å¾‘ (ä¾‹å¦‚: rankings/retro/overall/rankings_1500.json)
    # çµ„åˆ B: å¸¶ ID çš„æª”å (ä¾‹å¦‚: rankings/premier/overall/rankings_premier_2500.json)
    
    candidates = []
    
    # é‡å° "Ultra Premier" é€™ç¨®ç‰¹æ®Šæƒ…æ³ï¼Œå®ƒå¯èƒ½åœ¨ premier è³‡æ–™å¤¾ï¼Œä¹Ÿå¯èƒ½åœ¨ ultra_premier
    ids_to_try = [pvpoke_id]
    if pvpoke_id == "ultra_premier": ids_to_try.append("premier")
    if pvpoke_id == "premier": ids_to_try.append("ultra_premier")

    for pid in ids_to_try:
        # æª”åæ ¼å¼ 1: rankings_{cp}.json
        candidates.append(f"{base_repo}/{pid}/overall/rankings_{cp}.json")
        # æª”åæ ¼å¼ 2: rankings_{id}_{cp}.json
        candidates.append(f"{base_repo}/{pid}/overall/rankings_{pid}_{cp}.json")

    print(f"ğŸ” æ­£åœ¨åµæ¸¬ {pvpoke_id} (CP {cp})...")

    for url in candidates:
        try:
            # ä½¿ç”¨ HEAD è«‹æ±‚ (åªæŠ“æª”é ­ï¼Œä¸æŠ“å…§å®¹ï¼Œé€Ÿåº¦æ¥µå¿«ä¸”çœæµé‡)
            res = requests.head(url, headers=HEADERS, timeout=3)
            if res.status_code == 200:
                print(f"   âœ… æ‰¾åˆ°æœ‰æ•ˆæª”æ¡ˆ: {url}")
                return url
        except:
            pass
    
    print(f"   âŒ æ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•ˆæª”æ¡ˆ (å¯èƒ½ PvPoke å°šæœªæ›´æ–°)")
    return None

# ==========================================
# 3. çˆ¬èŸ²é‚è¼¯ (è§£æå®˜ç¶²)
# ==========================================
def get_leagues_from_article(url, lang="en"):
    soup = get_soup(url, lang)
    if not soup: return []
    
    items = soup.find_all('div', attrs={"data-slot": "GblScheduleBlockItem"})
    schedule_data = []
    
    for item in items:
        start_ts = int(item.get('data-start-timestamp', 0))
        end_ts = int(item.get('data-end-timestamp', 0))
        
        league_divs = item.find_all('div', class_=lambda x: x and 'League' in x)
        names = [d.get_text(strip=True).replace('*', '') for d in league_divs if d.get_text(strip=True)]
        
        schedule_data.append({"start": start_ts, "end": end_ts, "leagues": names})
    return schedule_data

def map_to_pvpoke_id_and_cp(en_name):
    name = en_name.lower()
    cp = 1500
    
    if "master" in name: cp = 10000
    elif "ultra" in name: cp = 2500
    elif "little" in name: cp = 500
    
    clean_name = name.replace(" cup", "").replace(" league", "").replace(" edition", "").replace(" version", "")
    
    if "great league" in name and "remix" not in name: return "all", 1500
    if "ultra league" in name and "premier" not in name: return "all", 2500
    if "master league" in name and "premier" not in name: return "all", 10000
    
    # ç‰¹æ®Šè™•ç†: Ultra Premier
    if "premier" in clean_name:
        if "ultra" in name: return "premier", 2500 # é€šå¸¸ Ultra Premier æ”¾åœ¨ premier è³‡æ–™å¤¾
        if "master" in name: return "premier", 10000
        return "premier", cp

    pvp_id = clean_name.strip().split(" ")[-1]
    
    manual_map = {
        "catch": "catch", "holiday": "holiday", "remix": "remix", 
        "retro": "retro", "fantasy": "fantasy", "willpower": "willpower", 
        "sunshine": "sunshine", "halloween": "halloween", "evolution": "evolution"
    }
    
    if pvp_id in manual_map: pvp_id = manual_map[pvp_id]
    return pvp_id, cp

# ==========================================
# 4. ä¸»ç¨‹å¼åŸ·è¡Œ
# ==========================================
def run_automation():
    base_url = "https://pokemongolive.com"
    news_list_url = f"{base_url}/zh_hant/news"
    
    soup = get_soup(news_list_url, "zh")
    if not soup: return

    zh_article_url = None
    for a in soup.find_all('a', href=True):
        if "å°æˆ°è¯ç›Ÿ" in a.get_text() and "è³½å­£æ›´æ–°" in a.get_text():
            href = a['href']
            zh_article_url = base_url + href if not href.startswith('http') else href
            break
    
    if not zh_article_url:
        print("âŒ æ‰¾ä¸åˆ°æœ€æ–°çš„å°æˆ°è¯ç›Ÿæ–‡ç« ")
        return

    en_article_url = re.sub(r'/zh[-_]hant/', '/en/', zh_article_url, flags=re.IGNORECASE)
    
    print(f"ğŸ”— ä¸­æ–‡: {zh_article_url}")
    print(f"ğŸ”— è‹±æ–‡: {en_article_url}")

    zh_data = get_leagues_from_article(zh_article_url, "zh")
    en_data = get_leagues_from_article(en_article_url, "en")
    
    current_ms = int(time.time() * 1000)
    
    manifest = {
        "last_updated_human": time.ctime(),
        "active_leagues": []
    }
    
    for i in range(len(zh_data)):
        if i >= len(en_data): break
        
        if zh_data[i]['start'] <= current_ms <= zh_data[i]['end']:
            for zh, en in zip(zh_data[i]['leagues'], en_data[i]['leagues']):
                pvp_id, cp = map_to_pvpoke_id_and_cp(en)
                
                # â˜…â˜…â˜… é—œéµï¼šåœ¨é€™è£¡é€²è¡Œç¶²å€åµæ¸¬ â˜…â˜…â˜…
                valid_url = find_valid_pvpoke_url(pvp_id, cp)
                
                if valid_url:
                    manifest["active_leagues"].append({
                        "name_zh": zh,
                        "name_en": en,
                        "pvpoke_id": pvp_id,
                        "cp": cp,
                        "json_url": valid_url # ç›´æ¥æŠŠæ¸¬è©¦æˆåŠŸçš„ç¶²å€å­˜é€²å»
                    })
                else:
                    print(f"âš ï¸ è·³é {zh}: PvPoke ä¸Šæ‰¾ä¸åˆ°å°æ‡‰æª”æ¡ˆ")

    os.makedirs('data', exist_ok=True)
    with open('data/manifest.json', 'w', encoding='utf-8') as f:
        json.dump(manifest, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ‰ æˆåŠŸç”¢å‡º {len(manifest['active_leagues'])} ç­†æœ‰æ•ˆè³‡æ–™ï¼")

if __name__ == "__main__":
    run_automation()
